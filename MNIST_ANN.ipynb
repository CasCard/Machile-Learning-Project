{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST_ANN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMOeknDW42Rorrq+yaQAs2B",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CasCard/Machine-Learning-Project/blob/master/MNIST_ANN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A04MWSkM3Jqo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82
        },
        "outputId": "1b8bdbff-a5cd-433c-f8bc-5a77e00d3ba9"
      },
      "source": [
        "from __future__ import print_function\n",
        "from six.moves import cPickle as pickle\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3sGjvU13yw2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mnist=tf.keras.datasets.mnist\n",
        "(x_train,y_train),(x_test,y_test)=mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ct41PPxZ4FJS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "6128090f-7a14-4c4b-f8ad-159a95b09a22"
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7uCPa_64tyk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "31653e2f-ade7-4104-fbc0-1847b96ac97b"
      },
      "source": [
        "x_test.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPI220a54ys0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset=x_train.reshape(x_train.shape[0],-1).T\n",
        "train_labels=y_train.reshape(y_train.shape[0],-1).T\n",
        "test_dataset=x_test.reshape(x_test.shape[0],-1).T\n",
        "test_labels=y_test.reshape(y_test.shape[0],-1).T"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDegNa195NKR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def One_hot_encoder(labels,C):\n",
        "    C=tf.constant(C,dtype=tf.int32,name='C')\n",
        "    encoded=tf.one_hot(labels,C)\n",
        "    with tf.Session() as sess:\n",
        "        return sess.run(encoded)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79dvDAiS5dSq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "3e976d18-9622-405f-b5db-912e26a1fd7a"
      },
      "source": [
        "Train_labels=One_hot_encoder(train_labels,10)\n",
        "#rint(Train_labels.shape)\n",
        "Train_labels=Train_labels[0]\n",
        "print(Train_labels.shape)\n",
        "#rint(train_labels[0])\n",
        "#rint(Train_labels[0][0])\n",
        "print(train_dataset.shape)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 10)\n",
            "(784, 60000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVH6IDuC5hMA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "ab1426ef-ce6b-49be-bbf5-f043094546d4"
      },
      "source": [
        "total_layers=7\n",
        "Layer_Units={1:38,2:38,3:38,4:38,5:38,6:38}\n",
        "Layer_Units[total_layers]=10\n",
        "cache={}\n",
        "for i in range(1,total_layers+1):\n",
        "    cache['Z'+str(i)]=0\n",
        "    cache['A'+str(i)]=0\n",
        "parameters={}\n",
        "count=1\n",
        "for i in Layer_Units:\n",
        "    num=i\n",
        "    weight=\"W\"+str(num)\n",
        "    bias='b'+str(num)\n",
        "    if i==1:\n",
        "        parameters[weight]=tf.get_variable(weight,[Layer_Units[i],784],initializer=tf.contrib.layers.xavier_initializer(seed=1))\n",
        "        parameters[bias] = tf.get_variable(bias, [Layer_Units[i], 1], initializer = tf.zeros_initializer())\n",
        "    else:\n",
        "        parameters[weight]=tf.get_variable(weight,[Layer_Units[i],Layer_Units[i-1]],initializer=tf.contrib.layers.xavier_initializer(seed=1)) \n",
        "        parameters[bias] = tf.get_variable(bias, [Layer_Units[i], 1], initializer = tf.zeros_initializer())"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4k7V-jPT5v5A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "2787e569-db6e-400c-8420-3b3af82fe3b6"
      },
      "source": [
        "print(train_dataset.shape)\n",
        "print(Train_labels.shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(784, 60000)\n",
            "(60000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8A8o4jHO5z93",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X=tf.placeholder(shape=[784,None],dtype=tf.float32)\n",
        "Y=tf.placeholder(shape=[None,10],dtype=tf.float32)\n",
        "for i in Layer_Units:\n",
        "        num=i\n",
        "        if i==1:\n",
        "            cache['Z'+str(i)]=tf.add(tf.matmul(parameters['W'+str(num)],X),parameters['b'+str(num)])\n",
        "            cache['A'+str(i)]=tf.nn.relu(cache['Z'+str(i)])   \n",
        "        elif i==total_layers:\n",
        "            cache['Z'+str(i)]=tf.add(tf.matmul(parameters['W'+str(num)],cache['A'+str(i-1)]),parameters['b'+str(num)])\n",
        "        else:\n",
        "            cache['Z'+str(i)]=tf.add(tf.matmul(parameters['W'+str(num)],cache['A'+str(i-1)]),parameters['b'+str(num)])\n",
        "            cache['A'+str(i)]=tf.nn.relu(cache['Z'+str(i)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVZH4utR54TS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "19c9cf47-8ec1-400b-fa7a-f34207e959e3"
      },
      "source": [
        "logits = tf.transpose(cache['Z'+str(total_layers)])\n",
        "labels = Y\n",
        "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = logits, labels =labels))\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
        "train_op = optimizer.minimize(cost)\n",
        "\n",
        "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(labels, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "count=1\n",
        "init = tf.global_variables_initializer()\n",
        "session=tf.Session()\n",
        "session.run(init)\n",
        "print('Number','Loss','Accuracy','Wright1')\n",
        "import time as t\n",
        "\n",
        "for i in range(500):\n",
        "        #print(Train_labels.shape)\n",
        "    A=t.time()    \n",
        "    session.run(train_op,{X:train_dataset,Y:Train_labels})\n",
        "    loss, acc = session.run([cost, accuracy],{X:train_dataset,Y:Train_labels})\n",
        "    print(count,':',loss,':',acc)\n",
        "    count=count+1\n",
        "\n",
        " \n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-11-965d68746ba9>:3: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n",
            "Number Loss Accuracy Wright1\n",
            "1 : 27.671719 : 0.10671667\n",
            "2 : 17.578167 : 0.0965\n",
            "3 : 11.8327265 : 0.10661667\n",
            "4 : 9.015185 : 0.11811667\n",
            "5 : 7.338157 : 0.12\n",
            "6 : 6.085718 : 0.12291667\n",
            "7 : 5.1462913 : 0.13261667\n",
            "8 : 4.5305176 : 0.1486\n",
            "9 : 4.179467 : 0.15781666\n",
            "10 : 3.9805958 : 0.16576667\n",
            "11 : 3.8325248 : 0.16738333\n",
            "12 : 3.6830213 : 0.16885\n",
            "13 : 3.5147583 : 0.16938333\n",
            "14 : 3.336293 : 0.16803333\n",
            "15 : 3.166402 : 0.16873333\n",
            "16 : 3.021378 : 0.16853334\n",
            "17 : 2.903941 : 0.16901666\n",
            "18 : 2.8081596 : 0.1694\n",
            "19 : 2.7237635 : 0.16921666\n",
            "20 : 2.6432369 : 0.17043333\n",
            "21 : 2.5645454 : 0.1743\n",
            "22 : 2.4902105 : 0.17915\n",
            "23 : 2.424011 : 0.18576667\n",
            "24 : 2.3672187 : 0.19213334\n",
            "25 : 2.3189785 : 0.19785\n",
            "26 : 2.27585 : 0.20483333\n",
            "27 : 2.2353835 : 0.21281667\n",
            "28 : 2.1969345 : 0.2207\n",
            "29 : 2.1603813 : 0.22903334\n",
            "30 : 2.126256 : 0.2396\n",
            "31 : 2.0937202 : 0.25131667\n",
            "32 : 2.0628989 : 0.26238334\n",
            "33 : 2.0335858 : 0.27376667\n",
            "34 : 2.0054703 : 0.283\n",
            "35 : 1.9788021 : 0.29276666\n",
            "36 : 1.9537252 : 0.30125\n",
            "37 : 1.9299377 : 0.31151667\n",
            "38 : 1.9071549 : 0.32151666\n",
            "39 : 1.8848414 : 0.33335\n",
            "40 : 1.8623528 : 0.34576666\n",
            "41 : 1.8396786 : 0.35648334\n",
            "42 : 1.8169174 : 0.36855\n",
            "43 : 1.7945532 : 0.3791\n",
            "44 : 1.7732487 : 0.38921666\n",
            "45 : 1.7536682 : 0.39795\n",
            "46 : 1.7355633 : 0.40461665\n",
            "47 : 1.7188734 : 0.41108334\n",
            "48 : 1.7016844 : 0.41823334\n",
            "49 : 1.6826336 : 0.42408332\n",
            "50 : 1.6622248 : 0.43118334\n",
            "51 : 1.6413125 : 0.43838334\n",
            "52 : 1.6206328 : 0.44568333\n",
            "53 : 1.6006192 : 0.45336667\n",
            "54 : 1.5811495 : 0.46088332\n",
            "55 : 1.5619073 : 0.46821666\n",
            "56 : 1.543126 : 0.47661668\n",
            "57 : 1.5249964 : 0.48348334\n",
            "58 : 1.5074799 : 0.49021667\n",
            "59 : 1.490563 : 0.49748334\n",
            "60 : 1.4743968 : 0.50406665\n",
            "61 : 1.4588511 : 0.5096\n",
            "62 : 1.4434909 : 0.51665\n",
            "63 : 1.4279522 : 0.5226667\n",
            "64 : 1.4120933 : 0.5291\n",
            "65 : 1.3961558 : 0.53466666\n",
            "66 : 1.3806448 : 0.5396\n",
            "67 : 1.3656139 : 0.54475\n",
            "68 : 1.3508359 : 0.55001664\n",
            "69 : 1.3361037 : 0.5549333\n",
            "70 : 1.3213178 : 0.5603833\n",
            "71 : 1.3066015 : 0.56593335\n",
            "72 : 1.2919273 : 0.57185\n",
            "73 : 1.2774359 : 0.5778667\n",
            "74 : 1.2631973 : 0.58325\n",
            "75 : 1.2491633 : 0.5879667\n",
            "76 : 1.2352117 : 0.5926667\n",
            "77 : 1.22135 : 0.5971\n",
            "78 : 1.2075679 : 0.60188335\n",
            "79 : 1.1940113 : 0.6059833\n",
            "80 : 1.1805855 : 0.61073333\n",
            "81 : 1.1672432 : 0.61623335\n",
            "82 : 1.1539761 : 0.62056667\n",
            "83 : 1.1407818 : 0.62448335\n",
            "84 : 1.1276692 : 0.62935\n",
            "85 : 1.1146263 : 0.6336\n",
            "86 : 1.101674 : 0.6382667\n",
            "87 : 1.0887554 : 0.6422\n",
            "88 : 1.0759995 : 0.6468\n",
            "89 : 1.0634203 : 0.6511833\n",
            "90 : 1.0509448 : 0.65611666\n",
            "91 : 1.0385065 : 0.6602833\n",
            "92 : 1.026166 : 0.66386664\n",
            "93 : 1.0139672 : 0.6680833\n",
            "94 : 1.0019535 : 0.6723833\n",
            "95 : 0.99012655 : 0.67618334\n",
            "96 : 0.9784878 : 0.6803333\n",
            "97 : 0.96707433 : 0.68373334\n",
            "98 : 0.9558539 : 0.68698335\n",
            "99 : 0.9448294 : 0.6911333\n",
            "100 : 0.93403524 : 0.69483334\n",
            "101 : 0.9234311 : 0.69883335\n",
            "102 : 0.9130156 : 0.7025333\n",
            "103 : 0.902794 : 0.70603335\n",
            "104 : 0.8927909 : 0.70958334\n",
            "105 : 0.8830142 : 0.7133667\n",
            "106 : 0.87347305 : 0.7166\n",
            "107 : 0.8641881 : 0.72008336\n",
            "108 : 0.85510004 : 0.72293335\n",
            "109 : 0.84617496 : 0.72578335\n",
            "110 : 0.83742094 : 0.7289\n",
            "111 : 0.82883877 : 0.7320667\n",
            "112 : 0.8204819 : 0.73441666\n",
            "113 : 0.81236875 : 0.73751664\n",
            "114 : 0.80451745 : 0.74008334\n",
            "115 : 0.79687655 : 0.7427\n",
            "116 : 0.78946173 : 0.745\n",
            "117 : 0.7821835 : 0.7478\n",
            "118 : 0.7750294 : 0.75056666\n",
            "119 : 0.76799 : 0.7532667\n",
            "120 : 0.76105326 : 0.75595\n",
            "121 : 0.75425273 : 0.75853336\n",
            "122 : 0.7476015 : 0.76075\n",
            "123 : 0.7411085 : 0.7636167\n",
            "124 : 0.7347285 : 0.76575\n",
            "125 : 0.728461 : 0.7681\n",
            "126 : 0.7223279 : 0.7701333\n",
            "127 : 0.71630126 : 0.77235\n",
            "128 : 0.7103531 : 0.77463335\n",
            "129 : 0.7045048 : 0.77716666\n",
            "130 : 0.6987831 : 0.7794167\n",
            "131 : 0.6932016 : 0.7819333\n",
            "132 : 0.6877432 : 0.78423333\n",
            "133 : 0.68232477 : 0.78655\n",
            "134 : 0.67696536 : 0.78833336\n",
            "135 : 0.6716539 : 0.79055\n",
            "136 : 0.6664094 : 0.79223335\n",
            "137 : 0.6612102 : 0.7942\n",
            "138 : 0.6561133 : 0.79618335\n",
            "139 : 0.65109366 : 0.79798335\n",
            "140 : 0.6461611 : 0.79976666\n",
            "141 : 0.6413043 : 0.80135\n",
            "142 : 0.63652045 : 0.80308336\n",
            "143 : 0.6317955 : 0.8043333\n",
            "144 : 0.62714744 : 0.8056667\n",
            "145 : 0.62255013 : 0.80721664\n",
            "146 : 0.61800754 : 0.8088\n",
            "147 : 0.61354667 : 0.8105\n",
            "148 : 0.6091384 : 0.8119\n",
            "149 : 0.60477394 : 0.81385\n",
            "150 : 0.60044825 : 0.8149667\n",
            "151 : 0.5961673 : 0.8171\n",
            "152 : 0.5919312 : 0.8182667\n",
            "153 : 0.58771235 : 0.81981665\n",
            "154 : 0.5835509 : 0.82115\n",
            "155 : 0.5794457 : 0.82281667\n",
            "156 : 0.5754063 : 0.8240833\n",
            "157 : 0.5714211 : 0.8254333\n",
            "158 : 0.5675155 : 0.82668334\n",
            "159 : 0.56365067 : 0.82775\n",
            "160 : 0.5598411 : 0.8289667\n",
            "161 : 0.5560989 : 0.8306\n",
            "162 : 0.5523853 : 0.83178335\n",
            "163 : 0.5486837 : 0.83318335\n",
            "164 : 0.5450493 : 0.83455\n",
            "165 : 0.5414983 : 0.8355167\n",
            "166 : 0.53801095 : 0.83673334\n",
            "167 : 0.5345429 : 0.8379833\n",
            "168 : 0.5311231 : 0.83916664\n",
            "169 : 0.52774084 : 0.84003335\n",
            "170 : 0.5244171 : 0.8411\n",
            "171 : 0.52117604 : 0.84195\n",
            "172 : 0.517998 : 0.84313333\n",
            "173 : 0.514853 : 0.8441667\n",
            "174 : 0.5117632 : 0.84508336\n",
            "175 : 0.5087306 : 0.84625\n",
            "176 : 0.50574386 : 0.8473\n",
            "177 : 0.5028021 : 0.84831667\n",
            "178 : 0.49991494 : 0.84915\n",
            "179 : 0.4970703 : 0.85015\n",
            "180 : 0.4942673 : 0.8513333\n",
            "181 : 0.49149135 : 0.8524\n",
            "182 : 0.4887479 : 0.8530333\n",
            "183 : 0.48604593 : 0.85403335\n",
            "184 : 0.48338622 : 0.85495\n",
            "185 : 0.4807709 : 0.85555\n",
            "186 : 0.47819257 : 0.8563833\n",
            "187 : 0.47565728 : 0.85705\n",
            "188 : 0.47315288 : 0.85796666\n",
            "189 : 0.47069088 : 0.8585\n",
            "190 : 0.46826777 : 0.85936666\n",
            "191 : 0.4658819 : 0.8602\n",
            "192 : 0.46353543 : 0.86086667\n",
            "193 : 0.46122128 : 0.86158335\n",
            "194 : 0.45892924 : 0.8622\n",
            "195 : 0.45665592 : 0.86291665\n",
            "196 : 0.4544056 : 0.86395\n",
            "197 : 0.45218125 : 0.86483335\n",
            "198 : 0.44997635 : 0.86575\n",
            "199 : 0.4477961 : 0.8666\n",
            "200 : 0.4456483 : 0.8672\n",
            "201 : 0.4435222 : 0.8679\n",
            "202 : 0.4414153 : 0.8689\n",
            "203 : 0.43934122 : 0.8696833\n",
            "204 : 0.4373061 : 0.87016666\n",
            "205 : 0.43529814 : 0.87043333\n",
            "206 : 0.433315 : 0.87086666\n",
            "207 : 0.4313662 : 0.8714833\n",
            "208 : 0.42944404 : 0.8721167\n",
            "209 : 0.42753667 : 0.8725833\n",
            "210 : 0.4256625 : 0.87331665\n",
            "211 : 0.4238183 : 0.87365\n",
            "212 : 0.42199484 : 0.87408334\n",
            "213 : 0.42018986 : 0.8745667\n",
            "214 : 0.41841412 : 0.87523335\n",
            "215 : 0.41666564 : 0.87596667\n",
            "216 : 0.4149266 : 0.8764\n",
            "217 : 0.4132008 : 0.87693334\n",
            "218 : 0.41149044 : 0.8775167\n",
            "219 : 0.409789 : 0.8778833\n",
            "220 : 0.4081129 : 0.87843335\n",
            "221 : 0.40644842 : 0.87906665\n",
            "222 : 0.40479693 : 0.87965\n",
            "223 : 0.4031627 : 0.8800833\n",
            "224 : 0.4015441 : 0.88045\n",
            "225 : 0.39993685 : 0.88091666\n",
            "226 : 0.3983434 : 0.8815\n",
            "227 : 0.3967581 : 0.8821167\n",
            "228 : 0.3951821 : 0.8827\n",
            "229 : 0.39362067 : 0.8833\n",
            "230 : 0.39207342 : 0.88378334\n",
            "231 : 0.39053977 : 0.8843167\n",
            "232 : 0.389017 : 0.8847833\n",
            "233 : 0.3875102 : 0.8853\n",
            "234 : 0.38601992 : 0.88563335\n",
            "235 : 0.3845443 : 0.88593334\n",
            "236 : 0.3830817 : 0.8864167\n",
            "237 : 0.38163385 : 0.88656664\n",
            "238 : 0.38020638 : 0.88708335\n",
            "239 : 0.37879357 : 0.88755\n",
            "240 : 0.37739426 : 0.8879333\n",
            "241 : 0.37601185 : 0.8882\n",
            "242 : 0.3746448 : 0.88875\n",
            "243 : 0.37328532 : 0.88905\n",
            "244 : 0.3719312 : 0.88956666\n",
            "245 : 0.3705831 : 0.89023334\n",
            "246 : 0.36925283 : 0.89056665\n",
            "247 : 0.36792675 : 0.8908167\n",
            "248 : 0.36660442 : 0.8914667\n",
            "249 : 0.36529467 : 0.89173335\n",
            "250 : 0.3639974 : 0.8921833\n",
            "251 : 0.36270854 : 0.8925667\n",
            "252 : 0.36142683 : 0.893\n",
            "253 : 0.36015633 : 0.8932667\n",
            "254 : 0.35889128 : 0.89356667\n",
            "255 : 0.3576342 : 0.89393336\n",
            "256 : 0.35638684 : 0.89433336\n",
            "257 : 0.35515356 : 0.89468336\n",
            "258 : 0.35393676 : 0.8951\n",
            "259 : 0.35273126 : 0.8954667\n",
            "260 : 0.35153523 : 0.8958167\n",
            "261 : 0.35034996 : 0.8961333\n",
            "262 : 0.34917766 : 0.8965833\n",
            "263 : 0.34801054 : 0.89695\n",
            "264 : 0.34685433 : 0.89738333\n",
            "265 : 0.3457105 : 0.8977\n",
            "266 : 0.34456927 : 0.89815\n",
            "267 : 0.34343502 : 0.8985\n",
            "268 : 0.34231082 : 0.89875\n",
            "269 : 0.3411918 : 0.89915\n",
            "270 : 0.34008086 : 0.8994833\n",
            "271 : 0.33898222 : 0.8998333\n",
            "272 : 0.3378945 : 0.90008336\n",
            "273 : 0.3368213 : 0.9005167\n",
            "274 : 0.33575675 : 0.9009333\n",
            "275 : 0.33469555 : 0.90131664\n",
            "276 : 0.33363938 : 0.9016\n",
            "277 : 0.33259797 : 0.90201664\n",
            "278 : 0.3315681 : 0.9024\n",
            "279 : 0.33054426 : 0.9027333\n",
            "280 : 0.32952985 : 0.90288335\n",
            "281 : 0.32852376 : 0.90325\n",
            "282 : 0.32752544 : 0.90355\n",
            "283 : 0.32653144 : 0.9037167\n",
            "284 : 0.32554302 : 0.9041167\n",
            "285 : 0.32456198 : 0.9043\n",
            "286 : 0.32358715 : 0.9044833\n",
            "287 : 0.32261744 : 0.9048667\n",
            "288 : 0.3216554 : 0.90531665\n",
            "289 : 0.32070255 : 0.90575\n",
            "290 : 0.3197559 : 0.90608335\n",
            "291 : 0.31881705 : 0.9062833\n",
            "292 : 0.3178849 : 0.9065167\n",
            "293 : 0.316957 : 0.9065833\n",
            "294 : 0.31604218 : 0.90695\n",
            "295 : 0.31513733 : 0.9072\n",
            "296 : 0.31424108 : 0.9073667\n",
            "297 : 0.313357 : 0.9075\n",
            "298 : 0.31248373 : 0.9077333\n",
            "299 : 0.31161803 : 0.908\n",
            "300 : 0.3107543 : 0.90828335\n",
            "301 : 0.30990085 : 0.9084833\n",
            "302 : 0.30905598 : 0.90861666\n",
            "303 : 0.3082152 : 0.90885\n",
            "304 : 0.30738705 : 0.90895\n",
            "305 : 0.30656758 : 0.9091333\n",
            "306 : 0.3057537 : 0.90931666\n",
            "307 : 0.3049444 : 0.90965\n",
            "308 : 0.30413735 : 0.90975\n",
            "309 : 0.3033446 : 0.90985\n",
            "310 : 0.30255404 : 0.91005\n",
            "311 : 0.3017756 : 0.9105167\n",
            "312 : 0.30100244 : 0.91073334\n",
            "313 : 0.3002341 : 0.91083336\n",
            "314 : 0.29947415 : 0.91111666\n",
            "315 : 0.29871714 : 0.91141665\n",
            "316 : 0.29796952 : 0.91143334\n",
            "317 : 0.2972228 : 0.9116833\n",
            "318 : 0.29647925 : 0.9119167\n",
            "319 : 0.2957399 : 0.912\n",
            "320 : 0.29500127 : 0.9124333\n",
            "321 : 0.2942705 : 0.9126\n",
            "322 : 0.29353878 : 0.9127833\n",
            "323 : 0.29280925 : 0.91295\n",
            "324 : 0.29208258 : 0.9131\n",
            "325 : 0.29135367 : 0.9134\n",
            "326 : 0.29062825 : 0.91366667\n",
            "327 : 0.28990418 : 0.91385\n",
            "328 : 0.2891806 : 0.9142\n",
            "329 : 0.2884595 : 0.9144167\n",
            "330 : 0.28774 : 0.91445\n",
            "331 : 0.2870231 : 0.91465\n",
            "332 : 0.28631094 : 0.91506666\n",
            "333 : 0.28559962 : 0.91535\n",
            "334 : 0.28488907 : 0.9157\n",
            "335 : 0.2841798 : 0.9159167\n",
            "336 : 0.2834733 : 0.9163167\n",
            "337 : 0.28276813 : 0.9165\n",
            "338 : 0.28206745 : 0.91646665\n",
            "339 : 0.28137353 : 0.9166833\n",
            "340 : 0.2806812 : 0.91676664\n",
            "341 : 0.27999228 : 0.9171\n",
            "342 : 0.27930406 : 0.9173\n",
            "343 : 0.2786245 : 0.91746664\n",
            "344 : 0.27795067 : 0.9177\n",
            "345 : 0.27728295 : 0.91803336\n",
            "346 : 0.27662167 : 0.9182\n",
            "347 : 0.27596772 : 0.91833335\n",
            "348 : 0.27531755 : 0.9184833\n",
            "349 : 0.27467373 : 0.9188\n",
            "350 : 0.2740321 : 0.919\n",
            "351 : 0.27339324 : 0.9191833\n",
            "352 : 0.2727612 : 0.91925\n",
            "353 : 0.2721367 : 0.91935\n",
            "354 : 0.27151397 : 0.91945\n",
            "355 : 0.27089423 : 0.91976666\n",
            "356 : 0.27027437 : 0.9198833\n",
            "357 : 0.2696585 : 0.92003334\n",
            "358 : 0.26904467 : 0.92011666\n",
            "359 : 0.26843637 : 0.92035\n",
            "360 : 0.2678287 : 0.9203167\n",
            "361 : 0.26722437 : 0.92046666\n",
            "362 : 0.26662314 : 0.9206833\n",
            "363 : 0.2660217 : 0.92085\n",
            "364 : 0.26542586 : 0.9210167\n",
            "365 : 0.26483548 : 0.9213\n",
            "366 : 0.26424778 : 0.9216\n",
            "367 : 0.26366293 : 0.92191666\n",
            "368 : 0.26308188 : 0.92193335\n",
            "369 : 0.26250136 : 0.92193335\n",
            "370 : 0.26192406 : 0.92216665\n",
            "371 : 0.2613458 : 0.92223334\n",
            "372 : 0.26077437 : 0.9224333\n",
            "373 : 0.26020384 : 0.92251664\n",
            "374 : 0.259639 : 0.9227167\n",
            "375 : 0.2590793 : 0.92298335\n",
            "376 : 0.258525 : 0.9230667\n",
            "377 : 0.257973 : 0.92328334\n",
            "378 : 0.25742367 : 0.9234333\n",
            "379 : 0.25687587 : 0.92356664\n",
            "380 : 0.25632995 : 0.92378336\n",
            "381 : 0.2557894 : 0.9241167\n",
            "382 : 0.2552521 : 0.9242667\n",
            "383 : 0.2547157 : 0.92436665\n",
            "384 : 0.25417954 : 0.92465\n",
            "385 : 0.25364646 : 0.9249333\n",
            "386 : 0.2531174 : 0.92505\n",
            "387 : 0.25258908 : 0.9251\n",
            "388 : 0.25206208 : 0.92518336\n",
            "389 : 0.2515374 : 0.9253333\n",
            "390 : 0.2510137 : 0.92541665\n",
            "391 : 0.25049466 : 0.9256667\n",
            "392 : 0.24997957 : 0.9256333\n",
            "393 : 0.2494646 : 0.92588335\n",
            "394 : 0.24895388 : 0.92595\n",
            "395 : 0.24844658 : 0.92611665\n",
            "396 : 0.24793956 : 0.92615\n",
            "397 : 0.2474363 : 0.9262667\n",
            "398 : 0.24693489 : 0.9263833\n",
            "399 : 0.24643229 : 0.9265\n",
            "400 : 0.24593282 : 0.9267\n",
            "401 : 0.24543706 : 0.92686665\n",
            "402 : 0.24494456 : 0.92696667\n",
            "403 : 0.2444542 : 0.92698336\n",
            "404 : 0.2439687 : 0.9271167\n",
            "405 : 0.24348453 : 0.92723334\n",
            "406 : 0.24300139 : 0.9274167\n",
            "407 : 0.24251842 : 0.92756665\n",
            "408 : 0.24203779 : 0.9278\n",
            "409 : 0.24155954 : 0.928\n",
            "410 : 0.24108362 : 0.92815\n",
            "411 : 0.24061112 : 0.92845\n",
            "412 : 0.24014154 : 0.92868334\n",
            "413 : 0.23967125 : 0.92868334\n",
            "414 : 0.23920377 : 0.92878336\n",
            "415 : 0.23874018 : 0.9288333\n",
            "416 : 0.23827961 : 0.92901665\n",
            "417 : 0.23782268 : 0.92915\n",
            "418 : 0.23736869 : 0.9292\n",
            "419 : 0.2369168 : 0.92946666\n",
            "420 : 0.23646569 : 0.92955\n",
            "421 : 0.2360207 : 0.92973334\n",
            "422 : 0.23557363 : 0.9299333\n",
            "423 : 0.23512845 : 0.93011665\n",
            "424 : 0.2346862 : 0.9303\n",
            "425 : 0.23424493 : 0.9302833\n",
            "426 : 0.23380625 : 0.93041664\n",
            "427 : 0.23336868 : 0.9306333\n",
            "428 : 0.23293468 : 0.93075\n",
            "429 : 0.2324997 : 0.93081665\n",
            "430 : 0.23206748 : 0.9310667\n",
            "431 : 0.2316407 : 0.93118334\n",
            "432 : 0.23121683 : 0.9312\n",
            "433 : 0.23079352 : 0.9314\n",
            "434 : 0.2303721 : 0.93165\n",
            "435 : 0.22995338 : 0.9318\n",
            "436 : 0.22953548 : 0.93188334\n",
            "437 : 0.22912091 : 0.9320833\n",
            "438 : 0.22870901 : 0.93225\n",
            "439 : 0.22829783 : 0.93238336\n",
            "440 : 0.22789092 : 0.9325167\n",
            "441 : 0.22748575 : 0.9325167\n",
            "442 : 0.22708268 : 0.93261665\n",
            "443 : 0.22668186 : 0.9328\n",
            "444 : 0.22628161 : 0.9329\n",
            "445 : 0.22588268 : 0.93296665\n",
            "446 : 0.22548597 : 0.9331\n",
            "447 : 0.22508939 : 0.9332833\n",
            "448 : 0.22469285 : 0.9335\n",
            "449 : 0.22429852 : 0.93365\n",
            "450 : 0.22390753 : 0.93368334\n",
            "451 : 0.22351715 : 0.9338\n",
            "452 : 0.22312848 : 0.9339167\n",
            "453 : 0.22273998 : 0.93415\n",
            "454 : 0.22235286 : 0.9342167\n",
            "455 : 0.22196637 : 0.93441665\n",
            "456 : 0.22158144 : 0.93455\n",
            "457 : 0.22119947 : 0.9346333\n",
            "458 : 0.22081839 : 0.93465\n",
            "459 : 0.22043736 : 0.93478334\n",
            "460 : 0.22005501 : 0.93486667\n",
            "461 : 0.21967253 : 0.935\n",
            "462 : 0.21928991 : 0.93516666\n",
            "463 : 0.2189102 : 0.93523335\n",
            "464 : 0.21853232 : 0.9354333\n",
            "465 : 0.21815503 : 0.9355\n",
            "466 : 0.21778184 : 0.93565\n",
            "467 : 0.21741003 : 0.93575\n",
            "468 : 0.21703626 : 0.93588334\n",
            "469 : 0.21666181 : 0.9360667\n",
            "470 : 0.21629296 : 0.9360833\n",
            "471 : 0.21592717 : 0.9361167\n",
            "472 : 0.2155642 : 0.93625\n",
            "473 : 0.21520345 : 0.93626666\n",
            "474 : 0.21484268 : 0.93635\n",
            "475 : 0.21448353 : 0.9364667\n",
            "476 : 0.21412657 : 0.93656665\n",
            "477 : 0.21377145 : 0.93655\n",
            "478 : 0.21341652 : 0.9367\n",
            "479 : 0.21306363 : 0.93685\n",
            "480 : 0.2127141 : 0.93693334\n",
            "481 : 0.21236706 : 0.93703336\n",
            "482 : 0.21202138 : 0.93715\n",
            "483 : 0.21167614 : 0.9373\n",
            "484 : 0.21133402 : 0.9374\n",
            "485 : 0.21099526 : 0.9375167\n",
            "486 : 0.21065608 : 0.9375833\n",
            "487 : 0.21031857 : 0.93755\n",
            "488 : 0.20998073 : 0.93763334\n",
            "489 : 0.2096454 : 0.9376\n",
            "490 : 0.20931509 : 0.9377\n",
            "491 : 0.20898327 : 0.9378167\n",
            "492 : 0.20865625 : 0.93796664\n",
            "493 : 0.20833099 : 0.93806666\n",
            "494 : 0.20800322 : 0.93811667\n",
            "495 : 0.20768237 : 0.9382667\n",
            "496 : 0.2073602 : 0.9382833\n",
            "497 : 0.20703603 : 0.93838334\n",
            "498 : 0.20671543 : 0.9385\n",
            "499 : 0.20639417 : 0.9387\n",
            "500 : 0.20607507 : 0.93871665\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A0twqUYz7Bd7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "cbbbf4d3-7c16-451c-9ff5-95cb881a9453"
      },
      "source": [
        "A=t.time()\n",
        "Test_labels=One_hot_encoder(test_labels,10)\n",
        "Test_labels=Test_labels.reshape((Test_labels.shape[1],-1))\n",
        "print(Test_labels.shape)\n",
        "acc=session.run(accuracy,{X:test_dataset,Y:Test_labels})\n",
        "print('Test Accuracy',acc)\n",
        "print('Testing Time',t.time()-A)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000, 10)\n",
            "Test Accuracy 0.9207\n",
            "Testing Time 0.07825279235839844\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gj41SMIg7FGc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
